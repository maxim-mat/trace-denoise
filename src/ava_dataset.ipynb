{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T16:40:20.361660Z",
     "start_time": "2025-12-04T16:40:19.927054Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_label_map(label_map_path):\n",
    "\n",
    "    item_id = None\n",
    "    item_name = None\n",
    "    items = {}\n",
    "\n",
    "    with open(label_map_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line.replace(\" \", \"\")\n",
    "            if line == \"item{\":\n",
    "                pass\n",
    "            elif line == \"}\":\n",
    "                pass\n",
    "            elif \"label_id\" in line:\n",
    "                item_id = int(line.split(\":\", 1)[1].strip()) - 1\n",
    "            elif \"name\" in line:\n",
    "                item_name = line.split(\":\", 1)[1].replace(\"'\", \"\").replace('\"', \"\").strip()\n",
    "\n",
    "            if item_id is not None and item_name is not None:\n",
    "                items[item_name] = item_id\n",
    "                item_id = None\n",
    "                item_name = None\n",
    "\n",
    "    return items"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:40:20.389220Z",
     "start_time": "2025-12-04T16:40:20.376405Z"
    }
   },
   "cell_type": "code",
   "source": "activities = read_label_map(r\"D:\\Projects\\ava\\ava_v2.1\\ava_action_list_v2.1.pbtxt\")",
   "id": "558626fa8d8ef89f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:43:52.982563Z",
     "start_time": "2025-12-04T16:43:52.978704Z"
    }
   },
   "cell_type": "code",
   "source": "print({f'{k}': v.split(\" \")[0] for v, k in activities.items()})",
   "id": "e6134f42fd7dba30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'bend/bow', '1': 'crawl', '2': 'crouch/kneel', '3': 'dance', '4': 'fall', '5': 'get', '6': 'jump/leap', '7': 'lie/sleep', '8': 'martial', '9': 'run/jog', '10': 'sit', '11': 'stand', '12': 'swim', '13': 'walk', '14': 'answer', '15': 'brush', '16': 'carry/hold', '17': 'catch', '18': 'chop', '19': 'climb', '20': 'clink', '21': 'close', '22': 'cook', '23': 'cut', '24': 'dig', '25': 'dress/put', '26': 'drink', '27': 'drive', '28': 'eat', '29': 'enter', '30': 'exit', '31': 'extract', '32': 'fishing', '33': 'hit', '34': 'kick', '35': 'lift/pick', '36': 'listen', '37': 'open', '38': 'paint', '39': 'play', '40': 'play', '41': 'play', '42': 'point', '43': 'press', '44': 'pull', '45': 'push', '46': 'put', '47': 'read', '48': 'ride', '49': 'row', '50': 'sail', '51': 'shoot', '52': 'shovel', '53': 'smoke', '54': 'stir', '55': 'take', '56': 'text', '57': 'throw', '58': 'touch', '59': 'turn', '60': 'watch', '61': 'work', '62': 'write', '63': 'fight/hit', '64': 'give/serve', '65': 'grab', '66': 'hand', '67': 'hand', '68': 'hand', '69': 'hug', '70': 'kick', '71': 'kiss', '72': 'lift', '73': 'listen', '74': 'play', '75': 'push', '76': 'sing', '77': 'take', '78': 'talk', '79': 'watch'}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T19:07:29.758776Z",
     "start_time": "2025-12-01T19:07:28.558142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_df = pd.read_csv(r\"D:\\Projects\\ava\\ava_v2.1\\ava_val_v2.1.csv\", names=['id', 'timestamp', 'x1', 'y1', 'x2', 'y2', 'action_id', 'person_id'])\n",
    "stochastic_df = pd.read_csv(r\"D:\\Projects\\ava\\ava_baseline_detections_val_v2.1\\ava_baseline_detections_val_v2.1.csv\", names=['id', 'timestamp', 'x1', 'y1', 'x2', 'y2', 'action_id', 'score'])"
   ],
   "id": "44658287bb65e365",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:33:08.887772Z",
     "start_time": "2025-12-01T20:33:08.882564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def reconstruct_prob_vector(k, p_k, num_classes, alpha=0.3):\n",
    "    \"\"\"\n",
    "    k           : index of predicted class (0-based)\n",
    "    p_k         : known probability of the predicted class\n",
    "    num_classes : total number of classes\n",
    "    alpha       : Dirichlet concentration parameter\n",
    "    \"\"\"\n",
    "    if not (0 < p_k < 1):\n",
    "        p_k = abs(p_k - 5e-5)\n",
    "\n",
    "    rest = num_classes - 1\n",
    "    q = np.random.dirichlet([alpha] * rest)\n",
    "    p = np.zeros(num_classes)\n",
    "    p[k] = p_k\n",
    "    p_rest = (1 - p_k) * q\n",
    "    p[np.arange(num_classes) != k] = p_rest\n",
    "\n",
    "    return p"
   ],
   "id": "e1cd327e79609815",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:36:07.167691Z",
     "start_time": "2025-12-01T20:34:27.375155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tokenized_traces = []\n",
    "sk_traces = []\n",
    "n_classes = len(activities)\n",
    "for trace_id in tqdm(target_df[\"id\"].unique()):\n",
    "    tokenized_traces.append([x - 1 for x in target_df[target_df[\"id\"] == trace_id][\"action_id\"].to_numpy()])\n",
    "    sk_activities = [x - 1 for x in stochastic_df[stochastic_df[\"id\"] == trace_id][\"action_id\"].to_numpy()]\n",
    "    sk_score = stochastic_df[stochastic_df[\"id\"] == trace_id][\"score\"].to_numpy()\n",
    "    sk_traces.append([reconstruct_prob_vector(act, score, n_classes) for act, score in zip(sk_activities, sk_score)])"
   ],
   "id": "f8d142d3fb132962",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe7416fd17de48dab4baf35ff318f25b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:57:08.941739Z",
     "start_time": "2025-12-01T20:57:08.864679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import chain\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoder.fit(np.array(list(chain.from_iterable(tokenized_traces))).reshape(-1, 1))\n",
    "one_hot_ava = [encoder.transform(np.array(x).reshape(-1, 1)) for x in tokenized_traces]"
   ],
   "id": "177d5d49442838f0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:02:36.742415Z",
     "start_time": "2025-12-01T21:02:32.983449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"../data/pickles/ava_unified.pkl\", \"wb\") as f:\n",
    "    pkl.dump({'target': one_hot_ava, 'stochastic': [np.array(x) for x in sk_traces]}, f)"
   ],
   "id": "22a1ee8fcb2937f5",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ad4e2c7ea0a48f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
