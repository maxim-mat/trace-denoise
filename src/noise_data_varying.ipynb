{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T19:37:37.295113Z",
     "start_time": "2025-03-18T19:37:31.903148Z"
    }
   },
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.stats import entropy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:37:57.634169Z",
     "start_time": "2025-03-18T19:37:57.631170Z"
    }
   },
   "cell_type": "code",
   "source": "data_path = r\"../data/pickles/50_salads_unified.pkl\"",
   "id": "ebd09f887034f394",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:37:57.844970Z",
     "start_time": "2025-03-18T19:37:57.792974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(data_path, \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "det, sto = data['target'], data['stochastic']"
   ],
   "id": "f4a1a317e5d7f549",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:38:07.793451Z",
     "start_time": "2025-03-18T19:38:07.788950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def average_entropy_sequence(seq):\n",
    "    return np.mean([entropy(x) for x in seq])\n",
    "\n",
    "def average_entropy_data(data):\n",
    "    return np.mean([average_entropy_sequence(x) for x in data])"
   ],
   "id": "5bcf69f181356482",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:39:59.585042Z",
     "start_time": "2025-03-18T19:38:22.651544Z"
    }
   },
   "cell_type": "code",
   "source": "average_entropy_data(det), average_entropy_data(sto)",
   "id": "7a1150fd737f07e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.24932393)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T20:03:08.706536Z",
     "start_time": "2025-03-18T20:03:08.700538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_beta_params(low, high, middle):\n",
    "    \"\"\"\n",
    "    Determines Beta parameters such that when sampling X ~ Beta(a, b)\n",
    "    and scaling alpha = low + (high - low) * X, we have P(alpha < 0.5) ≈ middle.\n",
    "    Here we fix a = 1 and solve for b.\n",
    "\n",
    "    Parameters:\n",
    "      low    : lower bound of the target range.\n",
    "      high   : upper bound of the target range.\n",
    "      middle : desired probability that alpha is less than 0.5.\n",
    "\n",
    "    Returns:\n",
    "      (a, b) : tuple of Beta parameters.\n",
    "    \"\"\"\n",
    "    a = 1.0\n",
    "    q = (0.5 - low) / (high - low)\n",
    "    b = np.log(1 - middle) / np.log(1 - q)\n",
    "    return a, b\n",
    "\n",
    "def sample_concentration_parameter(low=0.05, high=1, middle=0.8):\n",
    "    \"\"\"\n",
    "    Samples a concentration parameter α in [low, high] such that\n",
    "    P(α < 0.5) ≈ 0.8.\n",
    "    \"\"\"\n",
    "    a, b = get_beta_params(low, high, middle)\n",
    "    x = np.random.beta(a, b)\n",
    "    # Scale to [low, high]\n",
    "    alpha = low + (high - low) * x\n",
    "    return alpha\n",
    "\n",
    "def add_dirichlet_noise(p, alpha=0.1, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    p: original probability vector (e.g., one-hot)\n",
    "    alpha: concentration parameter for the Dirichlet distribution.\n",
    "           Lower alpha makes the Dirichlet sample more \"peaky\".\n",
    "    noise_level: mixing coefficient for the noise.\n",
    "    \"\"\"\n",
    "    # Generate a Dirichlet noise vector.\n",
    "    noise = np.random.dirichlet(np.ones_like(p) * alpha)\n",
    "    # Mix the original distribution with the noise.\n",
    "    perturbed = (1 - noise_level) * p + noise_level * noise\n",
    "    # Ensure it sums to 1.\n",
    "    perturbed /= perturbed.sum()\n",
    "    return perturbed"
   ],
   "id": "7561596fa90af524",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for trace in det:\n",
    "    alphas = [sample_concentration_parameter() for _ in range(trace.shape[0])]"
   ],
   "id": "59dbc33f3656d46a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
