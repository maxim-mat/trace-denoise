{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:35:19.548733800Z",
     "start_time": "2024-05-14T17:35:15.205233Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from dataset.dataset import SaladsDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tensorboardX import SummaryWriter\n",
    "from src.ddpm.ddmp_multinomial import Diffusion\n",
    "from src.ddpm.modules import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 10\n",
    "device = \"cuda\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:36:36.235807400Z",
     "start_time": "2024-05-14T17:36:36.220805900Z"
    }
   },
   "id": "d6037cd4c0361c41"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open(\"data/pickles/50_salads_one_hot.pkl\", \"rb\") as f:\n",
    "    dataset = pkl.load(f)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, train_size=0.8, shuffle=True, random_state=17)\n",
    "train_salads = SaladsDataset(train_dataset)\n",
    "test_salads = SaladsDataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_salads, batch_size=batch_size,\n",
    "                          collate_fn=lambda batch: pad_sequence(batch, batch_first=True, padding_value=-1))\n",
    "test_loader = DataLoader(test_salads, batch_size=batch_size,\n",
    "                         collate_fn=lambda batch: pad_sequence(batch, batch_first=True, padding_value=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:36:36.857824200Z",
     "start_time": "2024-05-14T17:36:36.806319900Z"
    }
   },
   "id": "651b866c67a2f3bd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 6584, 19])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_batch = next(iter(train_loader)).to(device)\n",
    "pg_batch.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:36:37.653818900Z",
     "start_time": "2024-05-14T17:36:37.405320600Z"
    }
   },
   "id": "20c508bd004ed241"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([20, 10, 6584, 19])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffuser = Diffusion()\n",
    "\n",
    "t = diffuser.sample_timesteps(20)\n",
    "batch_noise_steps, noise = diffuser.noise_data(pg_batch, t)\n",
    "# dims: t_noise, b, t_data, c \n",
    "batch_noise_steps.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:36:39.787948700Z",
     "start_time": "2024-05-14T17:36:39.762949300Z"
    }
   },
   "id": "3ab6634bdca0ea15"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoderLayer, LSTM\n",
    "\n",
    "# denoiser = Transformer(d_model=19, nhead=19, num_encoder_layers=2, batch_first=True).to(device)\n",
    "denoiser = LSTM(input_size=19, hidden_size=512, batch_first=True).to(device)\n",
    "out, (hn, cn) = denoiser(batch_noise_steps[0].to(device).float())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:36:41.518675600Z",
     "start_time": "2024-05-14T17:36:41.322674700Z"
    }
   },
   "id": "52fee52bca577f71"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 6584, 19])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_noise_steps[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T15:06:48.203899600Z",
     "start_time": "2024-05-12T15:06:48.188401100Z"
    }
   },
   "id": "cd24735b09f04321"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 6584, 19])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_batch.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T15:06:53.446901500Z",
     "start_time": "2024-05-12T15:06:53.415399800Z"
    }
   },
   "id": "aba6267c4f681919"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\everything\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "the feature number of src and tgt must be equal to d_model",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m trans \u001B[38;5;241m=\u001B[39m Transformer(d_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, nhead\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, num_encoder_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, num_decoder_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m trans(out, pg_batch)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\everything\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\everything\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\everything\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:204\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001B[0m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe batch number of src and tgt must be equal\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m src\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model \u001B[38;5;129;01mor\u001B[39;00m tgt\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model:\n\u001B[1;32m--> 204\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe feature number of src and tgt must be equal to d_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    206\u001B[0m memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(src, mask\u001B[38;5;241m=\u001B[39msrc_mask, src_key_padding_mask\u001B[38;5;241m=\u001B[39msrc_key_padding_mask,\n\u001B[0;32m    207\u001B[0m                       is_causal\u001B[38;5;241m=\u001B[39msrc_is_causal)\n\u001B[0;32m    208\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(tgt, memory, tgt_mask\u001B[38;5;241m=\u001B[39mtgt_mask, memory_mask\u001B[38;5;241m=\u001B[39mmemory_mask,\n\u001B[0;32m    209\u001B[0m                       tgt_key_padding_mask\u001B[38;5;241m=\u001B[39mtgt_key_padding_mask,\n\u001B[0;32m    210\u001B[0m                       memory_key_padding_mask\u001B[38;5;241m=\u001B[39mmemory_key_padding_mask,\n\u001B[0;32m    211\u001B[0m                       tgt_is_causal\u001B[38;5;241m=\u001B[39mtgt_is_causal, memory_is_causal\u001B[38;5;241m=\u001B[39mmemory_is_causal)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: the feature number of src and tgt must be equal to d_model"
     ]
    }
   ],
   "source": [
    "trans = Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6)\n",
    "trans(out, pg_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:43:07.176951800Z",
     "start_time": "2024-05-14T17:43:06.560950800Z"
    }
   },
   "id": "4741f3c10feabef9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c79844ce64aaa0b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
